{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLATON: PLanetary Atmospheric Transmission for Observer Noobs \n",
    "\n",
    "**PLATON** is an exoplanetary atmospheric retreival code that fits a sample transmission spectra to observational data from space telescopes. This examples will process the well constrained exoplanet HD2095458b.\n",
    "\n",
    "An **exoplanet** is a planet that orbits a star other than our own.\n",
    "\n",
    "A **transit** is the fortuitous event when the planet passes in front of its host star. The depth of a transit is related to the amount of starlight that is absorbed by the exoplanet's atmosphere.  \n",
    "An **eclipse** is the fortuitous event when the planet passes behind its host star. The depth of an eclipse is related to the amount of planetary thermal energy (IR emission) that is absorbed by the exoplanet's atmosphere above the photosphere (source of IR emission).  \n",
    "\n",
    "A **transmission spectrum** is a connected sequence of transit depths (area ratio of the planet-to-star size during transit: (Rp/Rs)^2 ) over a range of wavelengths. That is to say that the transit depth (i.e. relative absorption by (planet + atmosphere) / (size of star) ) changes with wavelength because the atmospheric particles (e.g. gas, clouds, haze) have wavelength dependent absoprtion properties -- the atmosphere absorbs more photons at the core of molecular features compared to the wings thereof.\n",
    "\n",
    "An **emission spectrum** is a connected sequence of eclipse depths (flux ratio of the planet-to-star emission during transit: Fp/Fs ) over a range of wavelengths. That is to say that the eclipse depth (i.e. relative emission by (planet + atmosphere) / (emission by star) ) changes with wavelength because the atmospheric particles (e.g. gas, clouds, haze) have wavelength dependent absoprtion properties -- the atmosphere absorbs more photons at the core of molecular features compared to the wings thereof.\n",
    "\n",
    "A **Retrieval** is the numerical process (usually *Bayesian*) to invert the transmission or emission spectrum (here transmission) into a measurement of the abundances of particles (gas, clouds, hazes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters\n",
    "\n",
    "### Planet/Star Parameters\n",
    "* `Rp` - radius of the planet in units of Jupiter Radii\n",
    "* `Rstar` - radius of the planet in units of Solar Radii\n",
    "* `Mp` - mass of the planet in units of Jupiter Mass \n",
    "\n",
    "### Temperature-Pressure Profile Parameters\n",
    "\n",
    "The thermal profile used in the model assumes the atmosphere to be in radiative equilibrium based upon the analytic radiative equilibrium temperature profile of Guillot 2010. This profile assumes one downwelling visible channels of radiation and one upwelling stream of thermal emission.\n",
    "\n",
    "* `Tirr` - temperature at the top of atmosphere in Kelvin\n",
    "* `logKir` - log of the Planck mean thermal infrared opacity\n",
    "* `logg1` - log of the ratio of the Planck mean opacities in the visible stream to the thermal stream\n",
    "\n",
    "### Chemistry Parameters\n",
    "* `logMet` - log Metallicity\n",
    "* `logCtoO` - log of the ratio Carbon to Oxygen abundance\n",
    "* `logPQC` - log of the pressure of Carbon quenching\n",
    "* `logPQN` - log of the pressure of Nitrogen quenching\n",
    "\n",
    "### Cloud Parameters\n",
    "* `logRayAmp` - log of the amplitude of Rayleigh scattering\n",
    "* `RaySlp` - Slope of Rayleigh scattering\n",
    "* `logPc` - Pressure level of cloud deck in mbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We are adding the reload functionality to this Jupyter notebook in case the user wishes to make on the fly changes to the included software packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are adding the reload functionality to this Jupyter notebook in case the user wishes to make on the fly changes to the included software packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the neccesary built in python libraries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate\n",
    "\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the figure dimensions to nominal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['figure.figsize'] = (5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have `emcee` installed, then this will load it.  \n",
    "If you do not already have `emcee` installed, then this install it first, then load it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import emcee\n",
    "except:\n",
    "    !pip install git+https://github.com/dfm/emcee\n",
    "    import emcee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have `nestle` installed, then this will load it.  \n",
    "If you do not already have `nestle` installed, then this install it first, then load it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import nestle\n",
    "except:\n",
    "    !pip install nestle\n",
    "    import nestle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have `platon` installed, then this will load it.  \n",
    "If you do not already have `platon` installed, then this install it first, then load it.  \n",
    "\n",
    "We are using my github fork because it includes modifications for plotting and usage of the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import platon\n",
    "    del platon\n",
    "except:\n",
    "    !pip install git+https://github.com/exowanderer/platon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have `pygtc` installed, then this will load it.  \n",
    "If you do not already have `pygtc` installed, then this install it first, then load it.  \n",
    "\n",
    "We are using my github fork because it includes modifications for plotting with mulitnest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pygtc import plotGTC\n",
    "except:\n",
    "    !pip install git+https://github.com/exowanderer/pygtc\n",
    "    from pygtc import plotGTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have `exomast_api` installed, then this will load it.  \n",
    "If you do not already have `exomast_api` installed, then this will install it first, then load it.\n",
    "\n",
    "We are using the github repo because it is not on PYPI or Conda yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from exomast_api import exoMAST_API\n",
    "except:\n",
    "    !pip install git+https://github.com/exowanderer/exomast_api\n",
    "    from exomast_api import exoMAST_API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are loading the necessary `platon` library functions, such as `platon.fit_info`, `platon.transit_depth_calculator`, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platon.fit_info import FitInfo\n",
    "from platon.retriever import Retriever\n",
    "from platon.constants import R_sun, R_jup, M_jup\n",
    "from platon.constants import METRES_TO_UM\n",
    "from platon.transit_depth_calculator import TransitDepthCalculator\n",
    "from platon.errors import AtmosphereError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define useful computation and plotting functions. These are not necessary for `platon` to operate; but they streamline the plotting procedures for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with a model that computes the high resolution atmospheric model from the best-fit (or other) parameters derived below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_model(result, fit_info, bayesian_model='emcee', wave_min=0.2e-6, wave_max=9.0e-6, n_theory_pts=500, include_condensation=True):\n",
    "\n",
    "    wavelengths_theory = np.linspace(wave_min, wave_max, n_theory_pts)\n",
    "    half_diff_lam = 0.5*np.median(np.diff(wavelengths_theory))\n",
    "\n",
    "    # Setup calculator to use the theoretical wavelengths\n",
    "    calculator = TransitDepthCalculator(include_condensation=include_condensation)\n",
    "    calculator.change_wavelength_bins(np.transpose([wavelengths_theory-half_diff_lam, wavelengths_theory+half_diff_lam]))\n",
    "\n",
    "    retriever._validate_params(fit_info, calculator)\n",
    "\n",
    "    # Allocate the best-fit parameters from the `result` class\n",
    "    if bayesian_model == 'multinest':\n",
    "        best_params_arr = result.samples[np.argmax(result.logl)]\n",
    "    elif bayesian_model == 'emcee':\n",
    "        best_params_arr = result.flatchain[np.argmax(result.flatlnprobability)]\n",
    "    else:\n",
    "        raise ValueError(\"Options for `bayesian_model` (-bm, --bayesianmodel) must be either 'multinest' or 'emcee'\")\n",
    "\n",
    "    best_params_dict = {key:val for key,val in zip(fit_info.fit_param_names, best_params_arr)}\n",
    "\n",
    "    # Set the static parameteres to the default values\n",
    "    for key in fit_info.all_params.keys():\n",
    "        if key not in best_params_dict.keys():\n",
    "            best_params_dict[key] = fit_info.all_params[key].best_guess\n",
    "\n",
    "    # Assign the best fit model parameters to necessary variables\n",
    "    Rs = best_params_dict['Rs']\n",
    "    Mp = best_params_dict['Mp']\n",
    "    Rp = best_params_dict['Rp']\n",
    "    T_eq = best_params_dict['T']\n",
    "    logZ = best_params_dict['logZ']\n",
    "    CO_ratio = best_params_dict['CO_ratio']\n",
    "    log_cloudtop_P = best_params_dict['log_cloudtop_P']\n",
    "    log_scatt_factor = best_params_dict['log_scatt_factor']\n",
    "    scatt_slope = best_params_dict['scatt_slope']\n",
    "    error_multiple = best_params_dict['error_multiple']\n",
    "    T_star = best_params_dict['T_star']\n",
    "\n",
    "    T_spot = best_params_dict['T_spot']\n",
    "    spot_cov_frac = best_params_dict['spot_cov_frac']\n",
    "    frac_scale_height = best_params_dict['frac_scale_height']\n",
    "    log_number_density = best_params_dict['log_number_density']\n",
    "    log_part_size = best_params_dict['log_part_size']\n",
    "    part_size_std = best_params_dict['part_size_std']\n",
    "    ri = best_params_dict['ri']\n",
    "\n",
    "    # Compute best-fit theoretical model\n",
    "    try:\n",
    "        wavelengths, calculated_depths = calculator.compute_depths(\n",
    "            Rs, Mp, Rp, T_eq, logZ, CO_ratio,\n",
    "            scattering_factor=10**log_scatt_factor, scattering_slope=scatt_slope,\n",
    "            cloudtop_pressure=10**log_cloudtop_P, T_star=T_star)\n",
    "        \n",
    "        return wavelengths, calculated_depths\n",
    "    except AtmosphereError as error_message:\n",
    "        return str(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next funciton computes the high resolution atmospheric model (see above) and plots the model with the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_high_res_model_and_data(wave_data, t_depths, td_errors, result, fit_info, bayesian_model='emcee', wave_min=0.2e-6, wave_max=9.0e-6, n_theory_pts=500, include_condensation=True):\n",
    "    # Plot the data on top of the best fit high-resolution model\n",
    "    \n",
    "    wave_min = wave_data.min()\n",
    "    wave_max = wave_data.max()\n",
    "    \n",
    "    computed_model = compute_new_model(result=result, fit_info=fit_info, bayesian_model=bayesian_model, \n",
    "                                                       wave_min=wave_min, wave_max=wave_max, n_theory_pts=n_theory_pts, \n",
    "                                                       include_condensation=include_condensation)\n",
    "\n",
    "    if isinstance(computed_model,str):\n",
    "        raise AtmosphereError(computed_model)\n",
    "    else:\n",
    "        wavelengths, calculated_depths = computed_model\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.errorbar(METRES_TO_UM * wave_data, t_depths, yerr=td_errors, fmt='.', color='k', zorder=100)\n",
    "    plt.plot(METRES_TO_UM * wavelengths, calculated_depths)\n",
    "\n",
    "    plt.xlabel(\"Wavelength (um)\")\n",
    "    plt.ylabel(\"Transit depth\")\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if bayesian_model == 'multinest':\n",
    "        plt.savefig('multinest_best_fit_{}.png'.format(time_stamp))\n",
    "    elif bayesian_model == 'emcee':\n",
    "        plt.savefig('emcee_best_fit_{}walkers_{}steps_{}.png'.format(nwalkers, nsteps, time_stamp))\n",
    "    else:\n",
    "        raise ValueError(\"Options for `bayesian_model` (-bm, --bayesianmodel) must be either 'multinest' or 'emcee'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function takes as input the output of either `emcee` or `nestle` and plots the marginalized distribution and correlation plots for the Bayesian analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gtc_platon(result, fit_info, time_stamp='NotGiven', \n",
    "                    bayesian_model='emcee', fit_param_names=None, \n",
    "                    nContourLevels=3, label_fontsize=10, \n",
    "                    tick_fontsize=7, figureSize=12):\n",
    "    \n",
    "    # GTC: Grand Triangle of Confusion; i.e. Prettier Corner Plot\n",
    "    if bayesian_model == 'multinest':\n",
    "        res_flatchain_df = DataFrame(result.samples.copy(), columns=fit_info.fit_param_names)\n",
    "    elif bayesian_model == 'emcee':\n",
    "        res_flatchain_df = DataFrame(result.flatchain.copy(), columns=fit_info.fit_param_names)\n",
    "    else:\n",
    "        raise ValueError(\"Options for `bayesian_model` (-bm, --bayesianmodel) must be either 'multinest' or 'emcee'\")\n",
    "    \n",
    "    if fit_param_names is None: fit_param_names = fit_info.fit_param_names\n",
    "    \n",
    "    if 'Rs' in fit_info.fit_param_names: res_flatchain_df['Rs'] = res_flatchain_df['Rs'] / R_sun\n",
    "    if 'Rp' in fit_info.fit_param_names: res_flatchain_df['Rp'] = res_flatchain_df['Rp'] / R_jup\n",
    "    if 'Mp' in fit_info.fit_param_names: res_flatchain_df['Mp'] = res_flatchain_df['Mp'] / M_jup\n",
    "    \n",
    "    pygtc_out = plotGTC(res_flatchain_df.values,\n",
    "                        weights=result.weights if bayesian_model == 'multimodel' else None,\n",
    "                        nContourLevels=nContourLevels, \n",
    "                        paramNames=fit_param_names,\n",
    "                        customLabelFont={'size':label_fontsize},\n",
    "                        customTickFont={'size':tick_fontsize},\n",
    "                        figureSize=figureSize);\n",
    "\n",
    "    if bayesian_model == 'multinest':\n",
    "        plt.savefig('multinest_gtc_{}.png'.format(time_stamp))\n",
    "    elif bayesian_model == 'emcee':\n",
    "        plt.savefig('emcee_gtc_{}walkers_{}steps_{}.png'.format(nwalkers, nsteps, time_stamp))\n",
    "    else:\n",
    "        raise ValueError(\"Options for `bayesian_model` (-bm, --bayesianmodel) must be either 'multinest' or 'emcee'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These helper functions simply store the measured transit depths of HD209458b at multiple wavelengths, by instrument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data processing and Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the input data for the retrieval algorithm using the `exomast_API` routines to access `exo.mast.stsci.edu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "https://exo.mast.stsci.edu/api/v0.1/exoplanets/identifiers/?name=HD 209458 b generated the error:\n<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b0775376a272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplanet_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HD 209458 b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhd209458b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexoMAST_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhd209458b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spectra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwave_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhd209458b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanetary_spectra_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/github/exomast_api/exomast_api/exomast_api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, planet_name, exomast_version, api_url, verbose, quickstart)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquickstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Default behaviour to grab the planetary identifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_identifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# Default behaviour to grab the planetary identifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/github/exomast_api/exomast_api/exomast_api.py\u001b[0m in \u001b[0;36mget_identifiers\u001b[0;34m(self, idx_list)\u001b[0m\n\u001b[1;32m    212\u001b[0m                             ' exist.')\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanet_identifier_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanet_ident_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# Store dictionary of planetary identification parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/github/exomast_api/exomast_api/exomast_api.py\u001b[0m in \u001b[0;36mcheck_request\u001b[0;34m(self, request_url, request_return)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'Internal Server Error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequest_return\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             raise HTTPError('{} generated the error:\\n{}'.format(request_url, \n\u001b[0;32m--> 100\u001b[0;31m                                                             request_return))\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_spectra_filelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: https://exo.mast.stsci.edu/api/v0.1/exoplanets/identifiers/?name=HD 209458 b generated the error:\n<html><title>500: Internal Server Error</title><body>500: Internal Server Error</body></html>"
     ]
    }
   ],
   "source": [
    "planet_name = 'HD 209458 b'\n",
    "hd209458b = exoMAST_API(planet_name)\n",
    "hd209458b.get_spectra()\n",
    "wave_bins, wave_errs, depths, errors = hd209458b.planetary_spectra_table.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base class for the `platon` retrieval algorithm. It contains all of the necessary functionality below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Retriever object\n",
    "retriever = Retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our initial guess for each of the fitted and non-fitted parameters that `platon` depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rs = hd209458b.Rs * R_sun\n",
    "Mp = hd209458b.Ms * M_jup\n",
    "Rp = hd209458b.Rp * R_jup\n",
    "T_eq = hd209458b.Tp\n",
    "T_star = exoplanet.Teff # Stellar Temperature\n",
    "\n",
    "logZ = 0\n",
    "CO_ratio = 0.53 # Solar\n",
    "log_cloudtop_P = 4 # deep\n",
    "log_scatt_factor = 0 # non existant\n",
    "scatt_slope = 4 # Rayleigh scattering\n",
    "error_multiple = 1 # helps with convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will wrapp all of the above parameters into the `platon` specific `fit_info` instance.  \n",
    "This is a method to contain all and only the necessary information to pass to `platon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a FitInfo object and set best guess parameters\n",
    "fit_info = retriever.get_default_fit_info(\n",
    "                        Rs=Rs, Mp=Mp, Rp=Rp, T=T_eq,\n",
    "                        logZ=logZ, CO_ratio=CO_ratio, \n",
    "                        log_cloudtop_P=log_cloudtop_P,\n",
    "                        log_scatt_factor=log_scatt_factor, \n",
    "                        scatt_slope=scatt_slope, \n",
    "                        error_multiple=error_multiple, \n",
    "                        T_star=T_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are adding our Bayesian priors onto the `platon` model format.  \n",
    "Only the parameters listed here will be varrid during the subsequence `emcee` or `nestle` Bayesian estimation routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add fitting parameters - this specifies which parameters you want to fit\n",
    "#e.g. since we have not included cloudtop_P, it will be fixed at the value specified in the constructor\n",
    "fit_info.add_gaussian_fit_param('Rs', 0.02*R_sun)\n",
    "fit_info.add_gaussian_fit_param('Mp', 0.04*M_jup)\n",
    "\n",
    "fit_info.add_uniform_fit_param('Rp', 0.9*R_guess, 1.1*R_guess)\n",
    "fit_info.add_uniform_fit_param('T', 0.5*T_guess, 1.5*T_guess)\n",
    "fit_info.add_uniform_fit_param(\"log_scatt_factor\", 0, 1)\n",
    "fit_info.add_uniform_fit_param(\"logZ\", -1, 3)\n",
    "fit_info.add_uniform_fit_param(\"log_cloudtop_P\", -0.99, 5)\n",
    "fit_info.add_uniform_fit_param(\"error_multiple\", 0.5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a time stamp label to associate all outputs from the same run through in the storage device (i.e. hard drive).  \n",
    "All outputs from this operation will have the same time stamp. We should avoid over writing new results with the same time stamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values for the `emcee` are a nominal starting position that will allow us to confirm that the code without programming fails. The results should not be taken as accurate or converged. To perform a robust analysis, we would need ~$10^6$ operations: i.e. nwalkers = 1000; nsteps = 1000. A full, converged chain may take 24+ hours to compute.\n",
    "\n",
    "Moroever, `emcee` is likely not the best approach to fully understand the atmospheric parameter space.  \n",
    "It is highly recommended to use `bayesian_model = 'multinest'`, which could take *3+ days* to converge; but is far more likely to accurately measure the parameter space.\n",
    "\n",
    "This setup will take ~1 minute to run; but the results are not converged, to say the least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_model = 'emcee' # 'multinest'\n",
    "nwalkers = 50\n",
    "nsteps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the powerhouse of the `platon` algorithm that operates either the `emcee` or `multinest` Bayesian models. \n",
    "\n",
    "We will use the emcee model because it is easier to control how long a completed (not converged) operation will take. Multinest (via `nestle`) is far more likely to accurate probe the full parameter space volume; but it could take ~3 days to converge. Emcee will most likely focus on one mode of many; but we can control how long our computers operate by setting the `nwalkers` and `nsteps` parameters above. \n",
    "\n",
    "The nominal use case has shown that each walker and step should take 0.1 seconds.\n",
    "\n",
    "That is to say that 50 walkers and 20 steps should take 0.1 x 50 x 20 = 100 seconds; and 1000 walkers and 1000 steps should take 0.1 x 1000 x 1000 = 100k seconds = ~28 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bayesian_model == 'multinest':\n",
    "    #Use Nested Sampling to do the fitting\n",
    "    # with ThreadPoolExecutor() as executor:\n",
    "    # with ProcessPoolExecutor() as executor:\n",
    "    with Pool(cpu_count()) as executor:\n",
    "        result = retriever.run_multinest(wave_bins, depths, errors, fit_info, nestle_kwargs={'pool':executor})#, 'bootstrap':0 # bootstrap for `dynesty`\n",
    "    \n",
    "    result_dict = {'samples':result.samples, 'weights':result.weights, 'logl':result.logl}\n",
    "    joblib.dump(result_dict, 'multinest_results_{}.joblib.save'.format(time_stamp))\n",
    "elif bayesian_model == 'emcee':\n",
    "    #Use Affine Invariant Ensemble MCMC  to do the fitting\n",
    "    result = retriever.run_emcee(wave_bins, depths, errors, fit_info, nwalkers=nwalkers, nsteps=nsteps)\n",
    "    \n",
    "    result_dict = {'flatchain':result.flatchain, 'flatlnprob':result.flatlnprobability, 'chain':result.chain, 'lnprob':result.lnprobability}\n",
    "    joblib.dump(result_dict, 'emcee_results_{}walkers_{}steps_{}.joblib.save'.format(nwalkers, nsteps, time_stamp))\n",
    "else:\n",
    "    raise ValueError(\"Options for `bayesian_model` (-bm, --bayesianmodel) must be either 'multinest' or 'emcee'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Next we will plot the best fit model to confirm that our fitting algorithm did not run off a cliff into an unphysical parameter space.  \n",
    "As long as the blue model is close to the black dots, then we should be happy.  \n",
    "\n",
    "To attain better convergence, we could modify the atmospheric model *or* iterate the Bayesian longer -- possibly with different priors or intial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the Range in Wavelength to plot high resolution figures\n",
    "wave_min = wave_bins.min()\n",
    "wave_max = wave_bins.max()\n",
    "print('{:.3f} - {:.1f} {}'.format(wave_min*1e6,wave_max*1e6, 'microns'))\n",
    "\n",
    "wave_data = np.mean(wave_bins, axis=1)\n",
    "\n",
    "plot_high_res_model_and_data(wave_data=wave_data, t_depths=depths, td_errors=errors, result=result, fit_info=fit_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will examine the distribution and correlations for each of our 8 parameters. The diagrams can be interpretted as:\n",
    "\n",
    "(1) The 1D histograms represent the 3-sigma width of the marginalized Bayesian Credible Regions: Bayesian version of *confidence interval*.\n",
    "\n",
    "(2) The 2D histograms represent the $N(N-1)/2$ combinations of correlations between each of our N parameters (N=8 here).  \n",
    "If the 2D histograms are reasonably circular, then we can assume that the correlations are Gaussian, that is to say that they reflect the intrinsic uncertainty of the measurements; as oppose to correlations between any 2 of the parameters.  \n",
    "If the 2D histograms show obvious structure (linear trensds, multimodel populations, etc), then we should assume that parameter correlations may have an effect on the reported values and uncertainties. \n",
    "\n",
    "If we a linear trend between two physically correlated values (i.e. Rp and Mp), then the explanation is trivial.  \n",
    "If find a linear trend between two parameters without any known correlations, then we should investigate more closely.  \n",
    "If we find a non-linear trend between any two parameters, it should be investigated more closely.  \n",
    "If we see a bimodel or multimodel distribution, then we should investigate further -- nominally, the solution may require more data, which would probably require more observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_param_names = ['Rs [Rsun]', 'Mp [Mjup]', 'Rp [Rjup]', 'T [K]', 'log(haze)', 'logZ [FeH]', 'log(P_c) [mbar]', 'err_mod']\n",
    "plot_gtc_platon(result, fit_info, bayesian_model='emcee', fit_param_names=fit_param_names, nContourLevels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Show Stored Best Fit Solution with Multinest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](multinest_best_fit_20181113065432.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Stored Grand Triangle of Confusion Solution with Multinest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](multinest_gtc_20181113065432.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
